{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2970526,"sourceType":"datasetVersion","datasetId":1820993}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:35:22.021995Z","iopub.execute_input":"2024-03-01T04:35:22.022355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/walmart-dataset/Walmart.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:35:42.186963Z","iopub.execute_input":"2024-03-01T04:35:42.187362Z","iopub.status.idle":"2024-03-01T04:35:42.208093Z","shell.execute_reply.started":"2024-03-01T04:35:42.187333Z","shell.execute_reply":"2024-03-01T04:35:42.206954Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:35:44.058738Z","iopub.execute_input":"2024-03-01T04:35:44.059202Z","iopub.status.idle":"2024-03-01T04:35:44.083092Z","shell.execute_reply.started":"2024-03-01T04:35:44.059168Z","shell.execute_reply":"2024-03-01T04:35:44.082179Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n0      1  05-02-2010    1643690.90             0        42.31       2.572   \n1      1  12-02-2010    1641957.44             1        38.51       2.548   \n2      1  19-02-2010    1611968.17             0        39.93       2.514   \n3      1  26-02-2010    1409727.59             0        46.63       2.561   \n4      1  05-03-2010    1554806.68             0        46.50       2.625   \n\n          CPI  Unemployment  \n0  211.096358         8.106  \n1  211.242170         8.106  \n2  211.289143         8.106  \n3  211.319643         8.106  \n4  211.350143         8.106  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>Date</th>\n      <th>Weekly_Sales</th>\n      <th>Holiday_Flag</th>\n      <th>Temperature</th>\n      <th>Fuel_Price</th>\n      <th>CPI</th>\n      <th>Unemployment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>05-02-2010</td>\n      <td>1643690.90</td>\n      <td>0</td>\n      <td>42.31</td>\n      <td>2.572</td>\n      <td>211.096358</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>12-02-2010</td>\n      <td>1641957.44</td>\n      <td>1</td>\n      <td>38.51</td>\n      <td>2.548</td>\n      <td>211.242170</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>19-02-2010</td>\n      <td>1611968.17</td>\n      <td>0</td>\n      <td>39.93</td>\n      <td>2.514</td>\n      <td>211.289143</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>26-02-2010</td>\n      <td>1409727.59</td>\n      <td>0</td>\n      <td>46.63</td>\n      <td>2.561</td>\n      <td>211.319643</td>\n      <td>8.106</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>05-03-2010</td>\n      <td>1554806.68</td>\n      <td>0</td>\n      <td>46.50</td>\n      <td>2.625</td>\n      <td>211.350143</td>\n      <td>8.106</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:35:45.971611Z","iopub.execute_input":"2024-03-01T04:35:45.972438Z","iopub.status.idle":"2024-03-01T04:35:45.999768Z","shell.execute_reply.started":"2024-03-01T04:35:45.972401Z","shell.execute_reply":"2024-03-01T04:35:45.998657Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"      Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n3218     23  24-06-2011    1434036.18             0        63.80       3.851   \n3032     22  27-08-2010    1081420.96             0        68.99       2.770   \n5929     42  13-05-2011     603024.75             0        74.04       4.202   \n748       6  24-09-2010    1275591.84             0        76.49       2.624   \n3444     25  30-04-2010     706924.02             0        50.97       2.921   \n490       4  08-04-2011    2074953.46             0        62.61       3.605   \n1652     12  12-08-2011     955913.68             0        91.04       3.701   \n3752     27  01-10-2010    1543532.83             0        70.19       2.840   \n3685     26  16-03-2012     919503.40             0        35.06       3.867   \n647       5  15-07-2011     283248.62             0        88.64       3.575   \n\n             CPI  Unemployment  \n3218  135.265267         4.781  \n3032  136.557015         8.433  \n5929  129.089000         8.494  \n748   213.115289         6.973  \n3444  203.650369         7.856  \n490   128.823806         5.946  \n1652  129.201581        13.503  \n3752  136.629757         8.021  \n3685  137.584387         7.467  \n647   215.925070         6.529  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>Date</th>\n      <th>Weekly_Sales</th>\n      <th>Holiday_Flag</th>\n      <th>Temperature</th>\n      <th>Fuel_Price</th>\n      <th>CPI</th>\n      <th>Unemployment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3218</th>\n      <td>23</td>\n      <td>24-06-2011</td>\n      <td>1434036.18</td>\n      <td>0</td>\n      <td>63.80</td>\n      <td>3.851</td>\n      <td>135.265267</td>\n      <td>4.781</td>\n    </tr>\n    <tr>\n      <th>3032</th>\n      <td>22</td>\n      <td>27-08-2010</td>\n      <td>1081420.96</td>\n      <td>0</td>\n      <td>68.99</td>\n      <td>2.770</td>\n      <td>136.557015</td>\n      <td>8.433</td>\n    </tr>\n    <tr>\n      <th>5929</th>\n      <td>42</td>\n      <td>13-05-2011</td>\n      <td>603024.75</td>\n      <td>0</td>\n      <td>74.04</td>\n      <td>4.202</td>\n      <td>129.089000</td>\n      <td>8.494</td>\n    </tr>\n    <tr>\n      <th>748</th>\n      <td>6</td>\n      <td>24-09-2010</td>\n      <td>1275591.84</td>\n      <td>0</td>\n      <td>76.49</td>\n      <td>2.624</td>\n      <td>213.115289</td>\n      <td>6.973</td>\n    </tr>\n    <tr>\n      <th>3444</th>\n      <td>25</td>\n      <td>30-04-2010</td>\n      <td>706924.02</td>\n      <td>0</td>\n      <td>50.97</td>\n      <td>2.921</td>\n      <td>203.650369</td>\n      <td>7.856</td>\n    </tr>\n    <tr>\n      <th>490</th>\n      <td>4</td>\n      <td>08-04-2011</td>\n      <td>2074953.46</td>\n      <td>0</td>\n      <td>62.61</td>\n      <td>3.605</td>\n      <td>128.823806</td>\n      <td>5.946</td>\n    </tr>\n    <tr>\n      <th>1652</th>\n      <td>12</td>\n      <td>12-08-2011</td>\n      <td>955913.68</td>\n      <td>0</td>\n      <td>91.04</td>\n      <td>3.701</td>\n      <td>129.201581</td>\n      <td>13.503</td>\n    </tr>\n    <tr>\n      <th>3752</th>\n      <td>27</td>\n      <td>01-10-2010</td>\n      <td>1543532.83</td>\n      <td>0</td>\n      <td>70.19</td>\n      <td>2.840</td>\n      <td>136.629757</td>\n      <td>8.021</td>\n    </tr>\n    <tr>\n      <th>3685</th>\n      <td>26</td>\n      <td>16-03-2012</td>\n      <td>919503.40</td>\n      <td>0</td>\n      <td>35.06</td>\n      <td>3.867</td>\n      <td>137.584387</td>\n      <td>7.467</td>\n    </tr>\n    <tr>\n      <th>647</th>\n      <td>5</td>\n      <td>15-07-2011</td>\n      <td>283248.62</td>\n      <td>0</td>\n      <td>88.64</td>\n      <td>3.575</td>\n      <td>215.925070</td>\n      <td>6.529</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Checking Data**","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-01T05:38:19.712315Z","iopub.execute_input":"2024-03-01T05:38:19.712734Z","iopub.status.idle":"2024-03-01T05:38:19.992545Z","shell.execute_reply.started":"2024-03-01T05:38:19.712697Z","shell.execute_reply":"2024-03-01T05:38:19.990853Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-01T04:35:51.435314Z","iopub.execute_input":"2024-03-01T04:35:51.435711Z","iopub.status.idle":"2024-03-01T04:35:51.462268Z","shell.execute_reply.started":"2024-03-01T04:35:51.435680Z","shell.execute_reply":"2024-03-01T04:35:51.460774Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6435 entries, 0 to 6434\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Store         6435 non-null   int64  \n 1   Date          6435 non-null   object \n 2   Weekly_Sales  6435 non-null   float64\n 3   Holiday_Flag  6435 non-null   int64  \n 4   Temperature   6435 non-null   float64\n 5   Fuel_Price    6435 non-null   float64\n 6   CPI           6435 non-null   float64\n 7   Unemployment  6435 non-null   float64\ndtypes: float64(5), int64(2), object(1)\nmemory usage: 402.3+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"dup=df.duplicated().sum()\ndup","metadata":{"execution":{"iopub.status.busy":"2024-03-01T05:38:25.935082Z","iopub.execute_input":"2024-03-01T05:38:25.935562Z","iopub.status.idle":"2024-03-01T05:38:25.966465Z","shell.execute_reply.started":"2024-03-01T05:38:25.935524Z","shell.execute_reply":"2024-03-01T05:38:25.964601Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dup\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mduplicated()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      2\u001b[0m dup\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing and some visualisation","metadata":{}},{"cell_type":"code","source":"plt.scatter(df[\"Store\"],df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df[\"Holiday_Flag\"],df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(df[\"Holiday_Flag\"],df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(df[\"Fuel_Price\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df[\"Fuel_Price\"],df[\"Weekly_Sales\"])\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df[\"Unemployment\"],df[\"Weekly_Sales\"])\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rename({\"Holiday_Flag\":\"Is_Holiday\"},axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"df[\"Date\"]=pd.to_datetime(df[\"Date\"], format = \"%d-%m-%Y\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Month\"]=df[\"Date\"].dt.month","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Year\"]=df[\"Date\"].dt.year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Quarter\"]=df[\"Date\"].dt.quarter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['week'] = df['Date'].dt.isocalendar().week","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['day_of_week'] = df['Date'].dt.day_name()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['month_name'] = df['Date'].dt.month_name()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_season(quarter):\n\n    '''this function is to get season according to quarter column'''\n\n    if quarter == 1:\n        return 'Winter'\n    elif quarter == 2:\n        return 'Spring'\n    elif quarter == 3:\n        return 'Summer'\n    else:\n        return 'Autumn'","metadata":{"execution":{"iopub.status.busy":"2024-03-01T05:38:05.611002Z","iopub.execute_input":"2024-03-01T05:38:05.611410Z","iopub.status.idle":"2024-03-01T05:38:05.617886Z","shell.execute_reply.started":"2024-03-01T05:38:05.611381Z","shell.execute_reply":"2024-03-01T05:38:05.616281Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df['season'] = df['Quarter'].apply(get_season)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data visualisation with feature columns","metadata":{}},{"cell_type":"code","source":"plt.scatter(df[\"Weekly_Sales\"],df[\"Month\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# sales are high in december","metadata":{}},{"cell_type":"code","source":"plt.bar(df[\"Month\"],df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(df[\"Temperature\"],df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(df[\"month_name\"],df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(df[\"Quarter\"],df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d=df['Is_Holiday'].value_counts()\nd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d=df['Year'].value_counts()\nd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d=df['Quarter'].value_counts()\nd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d=df['Month'].value_counts()\nd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df[\"Month\"],x=df[\"month_name\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"day_of_week\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(df[\"day_of_week\"],df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nsns.countplot(data = df, x = 'Store')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=df.groupby('Is_Holiday')[\"Weekly_Sales\"].mean()\nx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('Quarter')[\"Weekly_Sales\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=df,x=df[\"Is_Holiday\"],y=df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(\"Store\")[\"Weekly_Sales\"].sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('Year')['Weekly_Sales'].sum().sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (14, 6))\nsns.barplot(data = df,\n            x = 'Year',\n            y = 'Weekly_Sales',\n            estimator = np.sum,\n            ci = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lt.figure(figsize = (24, 6))\n\nsns.barplot(data=df,x=\"month_name\",y=\"Weekly_Sales\",estimator = np.sum,ci = False)\n# Add labels and title\n\nplt.title('Total Sales in each Month')\nplt.xlabel('Month', size = 13)\nplt.ylabel('Total Sales', size = 13)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(data=df,index='Year',columns='month_name',values='Weekly_Sales',aggfunc='sum')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16, 6))\nsns.barplot(data = df,\n            x = 'Year',\n            y = 'Weekly_Sales',\n            hue = 'Month',\n            estimator = np.sum,\n            ci = False)\n\n# Add labels and title\nplt.title('Total Sales for each Month in each Year')\nplt.xlabel('Year', size = 18)\nplt.ylabel('Total Sales', size = 18)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(data=df,\n               index='Year',\n                columns='Quarter',\n                 values=\"Weekly_Sales\",\n                 aggfunc='sum')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16, 6))\nsns.barplot(data = df,\n            x = 'Year',\n            y = 'Weekly_Sales',\n            hue = 'Quarter',\n            estimator = np.sum,\n           ci = False)\n\n# Add labels and title\nplt.title('Total Sales for each Season in each Year')\nplt.xlabel('Year', size = 15)\nplt.ylabel('Total Sales', size = 15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Correlation","metadata":{}},{"cell_type":"markdown","source":"**Pearson Correlation\nThe Pearson Correlation measures the linear dependence between two variables X and Y.\n\nThe resulting coefficient is a value between -1 and 1 inclusive, where:\n\n  - 1: Perfect positive linear correlation.\n -  0: No linear correlation, the two variables most likely do not affect each other.\n-  1: Perfect negative linear correlation.\n\n**","metadata":{}},{"cell_type":"markdown","source":"**P-Value**\n**What is this P-value? The P-value is the probability value that the correlation between these two variables is statistically significant. Normally, we choose a significance level of 0.05, which means that we are 95% confident that the correlation between the variables is significant.\n\nBy convention, when the\n\np-value is < 0.001: we say there is strong evidence that the correlation is significant.\np-value is < 0.05: there is moderate evidence that the correlation is significant.\np-value is < 0.1: there is weak evidence that the correlation is significant.\np-value is > 0.1: there is no evidence that the correlation is significant.**","metadata":{}},{"cell_type":"markdown","source":"**Fuel Price vs. Weekly Sales**","metadata":{}},{"cell_type":"code","source":"# Let's calculate the Pearson Correlation Coefficient and P-value of 'fuel_price' and 'weekly_sales':\nfrom scipy import stats\npearson_coef, p_value = stats.pearsonr(df['Fuel_Price'], df['Weekly_Sales'])\nprint(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (14, 5))\nsns.regplot(data = df, x = 'Fuel_Price', y = 'Weekly_Sales', color = '#145DA0', line_kws = {'color': 'red'})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Since the p-value is > 0.1, the correlation between fuel price and weekly sales is not statistically significant.\nFuel price does not seem like a good predictor of the weekly sales at all since the regression line is close to horizontal. Therefore, it's not a reliable variable.**","metadata":{}},{"cell_type":"markdown","source":"**Unemployment vs. Weekly Sales**","metadata":{}},{"cell_type":"code","source":"# Let's calculate the Pearson Correlation Coefficient and P-value of 'unemployment' and 'weekly_sales':\npearson_coef, p_value = stats.pearsonr(df['Unemployment'], df['Weekly_Sales'])\nprint(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (14, 5))\nsns.regplot(data = df, x = 'Unemployment', y = 'Weekly_Sales', color = '#145DA0', line_kws = {'color': 'red'})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** -Since the p-value is < 0.001, the correlation between unemployment and weekly sales is strong evidence that the correlation is significant.\n-Unemployment seems like a good predictor of the weekly sales, The higher the unemployment rate, the lower the weekly sales.**","metadata":{}},{"cell_type":"markdown","source":"**CPI vs. Weekly Sales**","metadata":{}},{"cell_type":"code","source":"# Let's calculate the Pearson Correlation Coefficient and P-value of cpi' and 'weekly_sales':\npearson_coef, p_value = stats.pearsonr(df['CPI'], df['Weekly_Sales'])\nprint(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (14, 5))\nsns.regplot(data = df, x = 'Temperature', y = 'Weekly_Sales', color = '#145DA0', line_kws = {'color': 'red'})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Since the p-value is < 0.05, the correlation between temperature and weekly sales is moderate evidence that the correlation is significant.\nTemperature seems like a good predictor of the weekly sales, The higher the Temperature rate, the lower the weekly sales.**","metadata":{}},{"cell_type":"code","source":"df[\"Temperature\"].corr(df[\"Weekly_Sales\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlations with weekly sales\ncorr = df[['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']].corr()['Weekly_Sales'].sort_values(ascending = False)\ncorr = corr.to_frame()\ncorr.style.background_gradient(cmap=\"RdYlBu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"df_copy = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Dropping Unnecessary Columns¶\n**","metadata":{}},{"cell_type":"markdown","source":"Let's drop columns 'date', 'year' and drop columns 'quarter' and 'month'since there are the same columns as 'season' and 'month_name'.\n\nIn the \"day_of_week\" column, Friday is the most frequent with 67.1% compared to other days, so the model will be biased to the class of Friday, so it prefers to drop this column to avoid underfitting.","metadata":{}},{"cell_type":"code","source":"df_copy.drop(['Date', 'Year', 'Quarter', 'Month', 'day_of_week'], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the data types\ndf_copy.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's handle store and holiday columns as categorical features, so we should convert them into categories (objects).bb\ndf_copy['Store'] = df_copy['Store'].astype('object')\ndf_copy['Is_Holiday'] = df_copy['Is_Holiday'].astype('object')\ndf_copy['week'] = df_copy['week'].astype('object')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_copy.dtypes\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">   Detecting And Removing The Outliers¶\n","metadata":{}},{"cell_type":"code","source":"cols = ['Fuel_Price', 'Temperature', 'CPI', 'Unemployment']\nplt.figure(figsize=(20,18))\nfor i,col in enumerate(cols):\n    print(i, col)\n    plt.subplot(3,2,i+1)\n    sns.boxplot(df_copy, x = col, color = 'red')\nplt.show()\n\nprint('Number of data rows: ', df_copy.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove outliers from the temperature column\ndf_copy.drop(df_copy[df_copy['Temperature'] < 7].index, axis = 0, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove outliers from the unemployment column\ndf_copy.drop(df_copy[df_copy['Unemployment'] < 4.6].index, axis = 0, inplace = True)\ndf_copy.drop(df_copy[df_copy['Unemployment'] > 10.5].index, axis = 0, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\nplt.figure(figsize=(20,18))\nfor i, col in enumerate(cols):\n    print(i, col)\n    plt.subplot(3,2,i+1)\n    sns.boxplot(df_copy, x = col, color = 'g')\nplt.show()\n\nprint('Number of data rows: ', df_copy.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df_copy.drop(\"Weekly_Sales\",axis=1)\ny=df_copy[\"Weekly_Sales\"]\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of data      : ', X.shape)\nprint('Shape of train data: ', X_train.shape)\nprint('Shape of test data : ', X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Transformation","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer\n\nfrom category_encoders import BinaryEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_copy.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data into Numerical Features and Categorical Features\nnum_features=df_copy.select_dtypes('number').columns.to_list()\nnum_features.remove(\"Weekly_Sales\")\n\ncat_features=df_copy.select_dtypes('object').columns.to_list()\n\nprint(num_features)\nprint(cat_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data transformation pipeline\npreprocessor=ColumnTransformer([\n                              ('num_features',StandardScaler(),num_features),\n                              ('cat_features',BinaryEncoder(),cat_features),\n])\n\n# Fitting the training data\npreprocessor.fit(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transform the training data\nX_train_transformed = preprocessor.transform(X_train)\n\n# Transform the testing data\nX_test_transformed = preprocessor.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"def model_evaluation(estimator, Training_Testing, X, y):\n\n    ''' This function is used to evaluate the model through RMSE and R2'''\n\n    # Y predict of X train or X test\n    predict_data = estimator.predict(X)\n\n    print(f'{Training_Testing} Accuracy: \\n')\n    print(f'-> Root Mean Squared Error: {round(np.sqrt(mean_squared_error(y, predict_data)), 2)}')\n    print(f'-> R-Squere score Training: {round(r2_score(y, predict_data) * 100, 2)} % \\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Distribution_Plot(estimator, Training_Testing, X, y, Title):\n\n    \"\"\"This function is used to perform some model evaluation using training and testing data \\\n    by plotting the distribution of the actual and predicted values of the training or testing data.\"\"\"\n\n    # Y predict of X train or X test\n    yhat = estimator.predict(X)\n\n    plt.figure(figsize=(14, 6))\n    ax1 = sns.distplot(y, hist = False, color = \"b\", label = f'Actual Values ({Training_Testing})')\n    ax2 = sns.distplot(yhat, hist = False, color = \"r\", label = f'Predicted Values ({Training_Testing})', ax = ax1)\n    plt.title(Title, size = 18)\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hyperparameter_tunning(estimator, X_train, y_train, param_grid, score = 'r2', n = 5):\n\n    '''This function is used to find the best set of hyperparameters for the model to optimize its performance'''\n    \n    \n    # Perform grid search\n    grid_search = GridSearchCV(estimator = estimator,\n                               param_grid = param_grid,\n                               scoring = score,\n                               cv = n)\n\n    # Fit the data\n    grid_search.fit(X_train,y_train)\n\n    best_params = grid_search.best_params_\n    best_score = grid_search.best_score_\n\n    # Print the best parameters and score\n    print(f'Best parameters: {best_params} \\n')\n    print(f'Best score: {best_score}')\n\n    # best estimator\n    best_estimator = grid_search.best_estimator_\n\n    return best_estimator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Linear regression**","metadata":{}},{"cell_type":"code","source":"Lr=LinearRegression()\nLr.fit(X_train_transformed,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Accuracy\nmodel_evaluation(Lr, 'Training', X_train_transformed, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figure 1: Plot of predicted values using the training data compared to the actual values of the training data.\nTitle = 'Distribution Plot of Predicted Value Using Training Data vs Training Data Distribution'\nDistribution_Plot(Lr, 'Training', X_train_transformed, y_train, Title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since there are no linear correlations between variables and targets, The model seems to be not doing well in learning from the training dataset, so we need to increase the complexity of this model. let's do Polynomial Features for the data before modeling.","metadata":{}},{"cell_type":"code","source":"# Polynomial Regression Model\nLR_pipe = Pipeline([('poly_feat', PolynomialFeatures()),\n                    ('lin_reg', LinearRegression())])\n\n# Define the parameter grid to search\nparam_grid = {'poly_feat__degree': [2, 3, 4]}\n\nbest_estimator = hyperparameter_tunning(LR_pipe, X_train_transformed, y_train, param_grid, score = 'r2', n = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regression Model after tuning\npoly_reg = best_estimator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Accuracy Afer tuning\nmodel_evaluation(poly_reg, 'Training', X_train_transformed, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figure 2: Plot of predicted values using the training data compared to the actual values of the training data.\nTitle = 'Distribution Plot of Predicted Value Using Training Data vs Training Data Distribution'\nDistribution_Plot(poly_reg, 'Training', X_train_transformed, y_train, Title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(poly_reg,'Testing',X_test_transformed,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figure 3: Plot of predicted value using the test data compared to the actual values of the test data.\nTitle='Distribution Plot of Predicted Value Using Test Data vs Data Distribution of Test Data'\nDistribution_Plot(poly_reg, 'Testing', X_test_transformed, y_test, Title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After testing the polynomial regression model, it became clear that the model had learned sufficiently, as its accuracy was 96.7 %.","metadata":{}},{"cell_type":"markdown","source":"**KNN Regressor**","metadata":{}},{"cell_type":"code","source":"Knn_reg=KNeighborsRegressor(n_neighbors=5)\nKnn_reg.fit(X_train_transformed,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(Knn_reg,'Training',X_train_transformed,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figure 1: Plot of predicted values using the training data compared to the actual values of the training data.\nTitle = 'Distribution Plot of Predicted Value Using Training Data vs Training Data Distribution'\nDistribution_Plot(Knn_reg, 'Training', X_train_transformed, y_train, Title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the parameter grid to search\nparam_grid = {'n_neighbors': [1, 3, 5, 7, 8, 9, 11, 13]}\n\nbest_estimator = hyperparameter_tunning(Knn_reg, X_train_transformed, y_train, param_grid, score = 'r2', n = 5)\n\nBest_KNN = best_estimator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Accuracy Afer tuning\nmodel_evaluation(Best_KNN, 'Training', X_train_transformed, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figure 2: Plot of predicted values using the training data compared to the actual values of the training data.\nTitle = 'Distribution Plot of Predicted Value Using Training Data vs Training Data Distribution'\nDistribution_Plot(Best_KNN, 'Training', X_train_transformed, y_train, Title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing Accuracy\nmodel_evaluation(Best_KNN, 'Testing', X_test_transformed, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After testing the KNN Regressor model, it became clear that it is a bad model with an accuracy of 50.25 % in comparison to the above algorithm we used (Linear Regression).","metadata":{}},{"cell_type":"markdown","source":"**Decision Tree Regressor**","metadata":{}},{"cell_type":"code","source":"Dt=DecisionTreeRegressor()\nDt.fit(X_train_transformed,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(Dt,'Trainig',X_train_transformed,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figure 1: Plot of predicted values using the training data compared to the actual values of the training data.\nTitle = 'Distribution Plot of Predicted Value Using Training Data vs Training Data Distribution'\nDistribution_Plot(Dt, 'Training', X_train_transformed, y_train, Title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model has overfitting, so let's improve it by tuning the hyperparameters.","metadata":{}},{"cell_type":"code","source":"param_grid={'max_depth':np.arange(2,15),\n            'min_samples_split': [10, 20, 30, 40, 50, 100, 200, 300]}\n\nbest_estimator = hyperparameter_tunning(Dt, X_train_transformed, y_train, param_grid, score = 'r2', n = 5)\n\nBest_Tree = best_estimator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(Best_Tree,'Training',X_test_transformed,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figure 2: Plot of predicted values using the training data compared to the actual values of the training data.\nTitle = 'Distribution Plot of Predicted Value Using Training Data vs Training Data Distribution'\nDistribution_Plot(Best_Tree, 'Training', X_train_transformed, y_train, Title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_evaluation(Best_Tree, 'Testing', X_test_transformed, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figure 3: Plot of predicted value using the test data compared to the actual values of the test data.\nTitle='Distribution Plot of Predicted Value Using Test Data vs Data Distribution of Test Data'\nDistribution_Plot(Best_Tree, 'Testing', X_test_transformed, y_test, Title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Random Forest Regressor**","metadata":{}},{"cell_type":"code","source":"# Random Forest regressor Model\nrf = RandomForestRegressor()\nrf.fit(X_train_transformed,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Accuracy\nmodel_evaluation(rf, 'Training', X_train_transformed, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figure 1: Plot of predicted values using the training data compared to the actual values of the training data.\nTitle = 'Distribution Plot of Predicted Value Using Training Data vs Training Data Distribution'\nDistribution_Plot(rf, 'Training', X_train_transformed, y_train, Title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing Accuracy\nmodel_evaluation(rf, 'Testing', X_test_transformed, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Making: Determining a Good Model Fit","metadata":{}},{"cell_type":"markdown","source":"Now that we have visualized the different models, and generated the R-squared and MSE values for the fits, how do we determine a good model fit?\n\nWhat is a good R-squared value?\nWhen comparing models,\n- the model with the higher R-squared value is a better fit for the data.\n\nWhat is a good MSE?\nWhen comparing models,\n- the model with the smallest MSE value is a better fit for the data.","metadata":{}},{"cell_type":"code","source":"# Conclusions\n- Sales tend to be higher in Summer.\n\n- The rate of sales on holidays is higher than on other days.\n\n- There is a high variance in weekly sales from one store to another.\n\n- Sales are affected by the unemployment rate, so the higher the unemployment rate, the lower the sales.\n\n- Comparing these four models, we conclude that The Linear Regression Model is the best model with an accuracy of 96.84 % to be able to predict weekly sales from our dataset.","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}